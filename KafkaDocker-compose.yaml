version: '3.8'

services:
  kafka:
    image: apache/kafka:3.8.0        # Официальный образ Apache Kafka 3.8.0 с поддержкой KRaft (без Zookeeper)
    container_name: kafka            # Явное имя контейнера — удобно для отладки и ссылок из других сервисов
    ports:
      - 9092:9092 # Порт для клиентских подключений (Kafka listeners для приложений: продюсеры, консьюмеры)
      - 9093:9093 # Порт для внутреннего контроллера Kafka (KRaft Controller, нужен только внутри кластера) можно удалить

    environment:
#      KAFKA_KRAFT_CLUSTER_ID: "fACyZ_cqRjyDWWyLbSKp-Q"
      CLUSTER_ID: "fACyZ_cqRjyDWWyLbSKp-Q"
      # Уникальный идентификатор кластера Kafka (в base64 формате), обязателен для KRaft
#      Kafka Cluster — это совокупность нескольких брокеров (узлов), которые координируются между собой.
#      Каждый брокер — это процесс Kafka, выполняющийся на отдельной машине или контейнере.

      # Генерируется через `kafka-storage.sh random-uuid`
      # Используется при инициализации storage

#      Storage в Kafka — это хранилище данных брокера, включающее:
#      Сегменты логов сообщений (партиции топиков)
#      → Пример: topic1-0.log, topic1-1.index, и т.п.
#      Метаданные кластера (в режиме KRaft)
#      → Пример: meta.properties — хранит cluster.id, node.id, epoch, и т.д.
#      Служебные топики Kafka
#      __consumer_offsets — хранит смещения (offsets)
#      __transaction_state — хранит информацию о транзакциях
#      __cluster_metadata — метаинформация в KRaft
#      Storage размещается:
#      в директории KAFKA_LOG_DIRS (у тебя: /var/lib/kafka/data)
#      может быть примонтирован как Docker volume

      KAFKA_NODE_ID: 1
      # Уникальный ID текущего узла Kafka (в рамках кластера)
      # Должен быть уникален для каждого брокера (если будет кластер)
#      Узел Kafka / Kafka Node / Broker — это один участник (процесс Kafka), обычно идентифицируется по node.id.


      KAFKA_PROCESS_ROLES: broker,controller
      # Задает роли, которые исполняет текущий узел
      # broker — принимает/отдает сообщения
      # controller — управляет метаданными (лидерство partition'ов, топики, ACL и др.)
      # Значение `broker,controller` означает "single-node" кластер (совмещены роли)

      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      # Какие протоколы и на каких интерфейсах слушает Kafka внутри контейнера
#     Kafka использует именованные протоколы (PLAINTEXT, SSL, SASL_PLAINTEXT, SASL_SSL, CONTROLLER), чтобы:
#     Обозначить, какой тип защиты используется на порту
#     Определить роль соединения (внешний клиент, межброкерное, контроллер-контроллер и т.п.)
#      | Имя протокола    | Назначение                               | Защита               |
#      | ---------------- | ---------------------------------------- | -------------------- |
#      | `PLAINTEXT`      | Без шифрования и авторизации             | нет                  |
#      | `SSL`            | Клиенты подключаются по TLS              | TLS (шифрование)     |
#      | `SASL_PLAINTEXT` | Авторизация через SASL, без шифрования   | авторизация, без TLS |
#      | `SASL_SSL`       | Авторизация + шифрование                 | SASL + TLS           |
#      | `CONTROLLER`     | Протокол связи между контроллерами KRaft | может быть PLAINTEXT |

      # PLAINTEXT — внешний интерфейс для клиентов
      # CONTROLLER — интерфейс для внутренней связи контроллеров

      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://host.docker.internal:9092
      #KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092

#      Kafka listeners определяют, на каких интерфейсах и портах брокер принимает подключения,
#      и какие протоколы безопасности использовать. Это фундаментальная часть конфигурации сетевого взаимодействия Kafka.
#      Kafka использует разные listeners для разных ролей и клиентов:
#      Внешние приложения: продюсеры, консьюмеры, Kafka Streams, Connect, etc.
#      Внутреннее взаимодействие между брокерами.
#      KRaft контроллеры (вместо Zookeeper).

      # Какой адрес Kafka будет **рекламировать** клиентам для подключения
      # `host.docker.internal` работает на Windows/macOS и позволяет Java-программе на хосте подключаться к контейнеру
      # Альтернатива для Linux: указывать IP хоста (например, 192.168.1.100)

      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT
      # Указывает, какие протоколы безопасности применяются к каждому типу listener'а

      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      # Указывает, какой listener используется контроллером
      # Важно, если у вас несколько listeners, чтобы Kafka не перепутала внешний и внутренний каналы

      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@localhost:9093'
      # Конфигурация кворума контроллеров в KRaft
#     Кворум контроллеров (Controller Quorum) в контексте Kafka KRaft (Kafka Raft metadata mode) —
#     это набор брокеров, которые исполняют роль контроллера и управляют метаданными всего кластера.
#     Это замена Zookeeper в Kafka 2.x и старше.

      # Формат: <nodeId>@<host>:<controllerPort>
      # localhost в этом контексте допустим, потому что брокер = контроллер в single-node режиме
      # Если делаешь кластер — указываешь имена других брокеров, напр: 1@kafka1:9093,2@kafka2:9093

      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      # Уровень репликации системного топика `__consumer_offsets`
#      Репликация в Kafka — это механизм копирования данных между брокерами, обеспечивающий отказоустойчивость и высокую доступность.
#      Когда ты создаёшь топик, ты указываешь:
#      partitions — количество партиций;
#      replication.factor — сколько копий (реплик) каждой партиции хранить.

#     Возможные значения и их смысл:
#       1 (минимум)
#       Только одна реплика — данные хранятся на одном брокере.
#     Нет отказоустойчивости: при падении этого брокера — offset'ы потеряются.
#       Допустимо только в development / single-node сценариях.
#       Kafka не стартует, если указано значение выше числа доступных брокеров.
#
#       2, 3, ... (в multi-broker конфигурации)
#     Репликация на нескольких брокерах:
#       Значение 2 → две копии каждой партиции __consumer_offsets;
#       Значение 3 (наиболее популярный выбор в продакшене) → три копии.
#     Обеспечивает отказоустойчивость: при падении 1 или 2 брокеров offset'ы сохраняются.
#     Используется совместно с параметрами:
#       min.insync.replicas (например, 2) — сколько реплик должно быть синхронны для записи;
#       acks=all у продюсера — гарантирует, что offset записан в N реплик.

      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 5000
      # Задержка перед началом ребалансировки consumer group'ов (в миллисекундах)

#      Ребалансировка (rebalance) в контексте Kafka — это процесс перераспределения partition'ов топика между консьюмерами внутри одной consumer group.
#      Kafka гарантирует, что каждый partition будет обрабатываться только одним consumer’ом из группы, чтобы не было конфликтов и дублирования обработки.
#      Когда что-то меняется, например:
#      запускается новый consumer,
#      один из consumer'ов "падает" или отключается,
#      появляется новый partition в топике,
#      Kafka инициирует ребалансировку: пересчитывает, как распределить partition'ы между всеми активными consumer'ами в группе.

      # Значение 0 = сразу балансировать, полезно в dev-сценариях
#      | Значение         | Что это значит                             | Когда использовать                                               |
#      | ---------------- | ------------------------------------------ | ---------------------------------------------------------------- |
#      | `0`              | Kafka **сразу** начинает ребалансировку    | Dev-сценарии, одиночный consumer, минимальная задержка           |
#      | `5000`           | Подождёт 5 секунд перед первым ребалансом  | Прод, если consumers стартуют почти одновременно                 |
#      | `10000` (дефолт) | Подождёт 10 секунд (значение по умолчанию) | Типичный случай, помогает собрать всех консьюмеров до ребаланса  |
#      | `30000` и выше   | Очень длинная задержка (30 сек+)           | Не рекомендуется без веских причин — может задерживать обработку |


      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      # Минимальное число in-sync реплик для логов транзакций (важно для exactly-once delivery)

#      In-Sync Replicas (ISR) — это подмножество реплик партиции Kafka, которые:
#      Находятся в режиме FOLLOWER или LEADER
#      Не отстают от лидера более чем на replica.lag.time.max.ms миллисекунд
#      Гарантированно приняли все данные, подтвержденные лидером

#      В Kafka каждая партиция может иметь несколько реплик (копий), распределённых по разным брокерам. Среди них один брокер — лидер (leader), остальные — фолловеры (followers).
#      Когда продюсер пишет сообщение:
#      Сначала оно попадает на лидера
#      Затем рассылается фолловерам
#      Только когда все ISR-реплики подтвердят получение (если acks=all), продюсер получает ACK

      # В single-node окружении обязательно = 1
#      | Параметр                                | Результат                                                                 |
#      | --------------------------------------- | ------------------------------------------------------------------------- |
#      | `min.isr = 1`, `replication.factor = 1` | Нет отказоустойчивости, но работает в single-node                         |
#      | `min.isr = 2`, `replication.factor = 3` | Устойчиво к падению одного брокера                                        |
#      | `min.isr = 3`, `replication.factor = 3` | Устойчиво к потере данных, но любые задержки выводят партиции из ISR      |
#      | `min.isr > replication.factor`          | Kafka не сможет принять транзакции и заблокирует транзакционные продюсеры |


      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      # Репликация логов транзакций
      # Значение 1 допустимо только в одноброкерной конфигурации
#      | Значение репликации  | Что означает                            | Влияние и применение                                                                                                                                                                                                 |
#      | -------------------- | --------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
#      | 1                    | **Одна реплика** (single-node setup)    | Минимум для запуска одноброкерного кластера. Нет отказоустойчивости — при падении брокера теряется состояние транзакций.                                                                                             |
#      | > 1 (например, 2, 3) | Несколько реплик (multi-broker cluster) | Обеспечивает отказоустойчивость: если брокер с главной копией лога упал, другие реплики сохранят состояние транзакций. Улучшает надёжность и консистентность. Требует наличие минимум такого же количества брокеров. |
#      | = числу брокеров     | Максимально возможная репликация        | Максимальная отказоустойчивость, но и нагрузка на сеть и диски увеличивается.                                                                                                                                        |


      KAFKA_LOG_DIRS: /var/lib/kafka/data
      # Путь к директории, где Kafka хранит сегменты логов, топики, state
      # Этот путь монтируется через volume

    volumes:
      - kafka_data:/var/lib/kafka/data
    # Хранение данных Kafka между перезапусками контейнера
    # Если volume будет удалён — Kafka потребует повторной инициализации storage

volumes:
  kafka_data: